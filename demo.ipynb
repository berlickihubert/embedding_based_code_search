{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcb65c4",
   "metadata": {},
   "source": [
    "# Code API for custom database\n",
    "Iâ€™ve implemented two models. For a given query, we search for the closest solutions in two embedding spaces: one generated by the NLP model **sentence-transformers/all-MiniLM-L6-v2**, which embeds function names, and another generated by **codesage/codesage-base-v2**, which embeds function bodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7757d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing query vector database file.\n",
      "No existing code vector database file.\n",
      "Using device for nlp embedding model: cuda\n",
      "Using device for code embedding model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLP model results:\n",
      "Function name match: 1 with distance 0.3948790431022644 : add_numbers\n",
      "Function name match: 3 with distance 0.5458637475967407 : multiply_numbers\n",
      "Function name match: 2 with distance 0.5667691230773926 : subtract_numbers\n",
      "Function name match: 18 with distance 0.6176607608795166 : sum_list\n",
      "Function name match: 50 with distance 0.6925162672996521 : count_digits\n",
      "Function name match: 25 with distance 0.7290886044502258 : fibonacci\n",
      "Function name match: 4 with distance 0.741529107093811 : divide\n",
      "Function name match: 10 with distance 0.7870303392410278 : factorial\n",
      "Function name match: 23 with distance 0.8031855225563049 : count_occurrences\n",
      "Function name match: 46 with distance 0.804297685623169 : has_duplicates\n",
      "\n",
      "Code model results:\n",
      "Function body match: 1 with distance 0.38877278566360474 : add_numbers\n",
      "Function body match: 3 with distance 0.7932268381118774 : multiply_numbers\n",
      "Function body match: 2 with distance 0.8255326747894287 : subtract_numbers\n",
      "Function body match: 32 with distance 0.8936209082603455 : merge_lists\n",
      "Function body match: 40 with distance 0.9243806004524231 : list_to_string\n",
      "Function body match: 25 with distance 0.9301557540893555 : fibonacci\n",
      "Function body match: 8 with distance 0.9325319528579712 : is_odd\n",
      "Function body match: 28 with distance 0.94135582447052 : f_to_c\n",
      "Function body match: 50 with distance 0.9469057321548462 : count_digits\n",
      "Function body match: 27 with distance 0.9484638571739197 : c_to_f\n"
     ]
    }
   ],
   "source": [
    "from code_search_api import CodeSearchAPI\n",
    "\n",
    "api = CodeSearchAPI()\n",
    "api.create_vector_db(\"demo_code_repository/example_code_file_1.py\")\n",
    "functions = api.extract_function_bodies(\"demo_code_repository/example_code_file_1.py\")\n",
    "\n",
    "(nlp_model_results, code_model_results) = api.search(\"function that adds two numbers\")\n",
    "\n",
    "print()\n",
    "print(\"NLP model results:\")\n",
    "for match in nlp_model_results:\n",
    "    print(f\"Function name match: {match.key} with distance {match.distance} : {functions[match.key - 1][0]}\")\n",
    "\n",
    "print()\n",
    "print(\"Code model results:\")\n",
    "for match in code_model_results:\n",
    "    print(f\"Function body match: {match.key} with distance {match.distance} : {functions[match.key - 1][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e80cb",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "I evaluated the model on the *test* split of the **CoSQA** dataset.\n",
    "\n",
    "**Recall@10**:\n",
    "\n",
    "$$\n",
    "\\text{Recall@10} = \\frac{\\text{Number of occurrences of the desired object within top 10 retrieved results}}{\\text{Total size of the evaluation dataset}}\n",
    "$$\n",
    "\n",
    "**MRR@10**:  \n",
    "Measures the average reciprocal rank of the first relevant result within the top 10 retrieved results.  \n",
    "$$\n",
    "\\text{MRR@10} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{1}{\\text{rank}_i}\n",
    "$$\n",
    "\n",
    "\n",
    "**NDCG@10**:  \n",
    "Evaluates the ranking quality by assigning higher importance to relevant items appearing near the top of the ranked list.  \n",
    "\n",
    "$$\n",
    "\\text{NDCG@10} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{1}{\\log_2(\\text{rank}_i + 1)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "We can notice that in the CoSQA dataset, the function bodies include descriptions, so we embed those descriptions instead of the function names using our NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b919ad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded.\n",
      "Query vector database loaded from file\n",
      "No existing code vector database file.\n",
      "Using device for code embedding model: cuda\n",
      "Using device for nlp embedding model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 20150/20604\n",
      "Processing row 20200/20604\n",
      "Processing row 20250/20604\n",
      "Processing row 20300/20604\n",
      "Processing row 20350/20604\n",
      "Processing row 20400/20604\n",
      "Processing row 20450/20604\n",
      "Processing row 20500/20604\n",
      "Processing row 20550/20604\n",
      "Processing row 20600/20604\n",
      "Datasets loaded.\n",
      "Query vector database loaded from file\n",
      "Code vector database loaded from file\n",
      "Using device for code embedding model: cuda\n",
      "Using device for nlp embedding model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall@10 for code embeddings: 448/500 = 0.8960\n",
      "Recall@10 for query embeddings: 440/500 = 0.8800\n",
      "\n",
      "MRR@10 for code embeddings: 377.2884920634921/500 = 0.7546\n",
      "MRR@10 for query embeddings: 324.3527777777777/500 = 0.6487\n",
      "\n",
      "NDCG@10 for code embeddings: 395.1079768572858/500 = 0.7902\n",
      "NDCG@10 for query embeddings: 352.5450813293562/500 = 0.7051\n"
     ]
    }
   ],
   "source": [
    "from create_vector_db_from_CoSQA import create_vector_db_from_cosqa\n",
    "from evaluate_model import evaluate_model\n",
    "\n",
    "create_vector_db_from_cosqa()\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab4b86",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a6804",
   "metadata": {},
   "source": [
    "As it's only a demonstration for saving time I will only finetune **codesage** code model. First experiment on test split of dataset to check if it overfits \"correctly\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff7d2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on test split (for demonstration purposes to check if model works we try to overfit first).\n",
      "Datasets loaded.\n",
      "Number of batches in training data: 167\n",
      "Using device for code embedding model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/167\n",
      "Batch 100/167\n",
      "Batch 150/167\n",
      "Error in batch 164 : CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 13.69 GiB is allocated by PyTorch, and 602.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Epoch 1, Loss: 0.3219295811956514\n",
      "Total errors during training: 1\n",
      "\n",
      "Creating vector DB from CoSQA corpus with fine-tuned model and evaluating.\n",
      "Datasets loaded.\n",
      "Query vector database loaded from file\n",
      "No existing code vector database file.\n",
      "Using device for code embedding model: cuda\n",
      "Loaded model weights from fine-tuned_models/code_model_finetuned_test.pth\n",
      "Using device for nlp embedding model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 20150/20604\n",
      "Processing row 20200/20604\n",
      "Processing row 20250/20604\n",
      "Processing row 20300/20604\n",
      "Processing row 20350/20604\n",
      "Processing row 20400/20604\n",
      "Processing row 20450/20604\n",
      "Processing row 20500/20604\n",
      "Processing row 20550/20604\n",
      "Processing row 20600/20604\n",
      "\n",
      "Evaluating fine-tuned model on CoSQA test set.\n",
      "Datasets loaded.\n",
      "Query vector database loaded from file\n",
      "Code vector database loaded from file for finetuned model\n",
      "Using device for code embedding model: cuda\n",
      "Loaded model weights from fine-tuned_models/code_model_finetuned_test.pth\n",
      "Using device for nlp embedding model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall@10 for code embeddings: 492/500 = 0.9840\n",
      "Recall@10 for query embeddings: 440/500 = 0.8800\n",
      "\n",
      "MRR@10 for code embeddings: 443.9440476190475/500 = 0.8879\n",
      "MRR@10 for query embeddings: 324.3527777777777/500 = 0.6487\n",
      "\n",
      "NDCG@10 for code embeddings: 456.1547442424455/500 = 0.9123\n",
      "NDCG@10 for query embeddings: 352.5450813293562/500 = 0.7051\n"
     ]
    }
   ],
   "source": [
    "from evaluate_model import evaluate_model\n",
    "from create_vector_db_from_CoSQA import create_vector_db_from_cosqa\n",
    "from fine_tune_model_code import fine_tune_code_model\n",
    "\n",
    "print(\"Training on test split (for demonstration purposes to check if model works we try to overfit first).\")\n",
    "fine_tune_code_model(split=\"test\")\n",
    "\n",
    "print(\"\\nCreating vector DB from CoSQA corpus with fine-tuned model and evaluating.\")\n",
    "create_vector_db_from_cosqa(code_model_path=\"fine-tuned_models/code_model_finetuned_test.pth\")\n",
    "\n",
    "print(\"\\nEvaluating fine-tuned model on CoSQA test set.\")\n",
    "evaluate_model(code_model_path=\"fine-tuned_models/code_model_finetuned_test.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e4c575",
   "metadata": {},
   "source": [
    "As we can see after overfitting we reach Recall@10 = 0.9840 MRR@10 = 0.8109 and NDCG@10 = 0.8540 which is an improvement!\n",
    "Let's try again (on the train split of dataset this time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80367b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on train split\n",
      "\n",
      "Creating vector DB from CoSQA corpus with fine-tuned model and evaluating.\n",
      "Datasets loaded.\n",
      "Query vector database loaded from file\n",
      "Code vector database loaded from file\n",
      "Using device for code embedding model: cuda\n",
      "Loaded model weights from fine-tuned_models/code_model_finetuned_train.pth\n",
      "Using device for nlp embedding model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 20150/20604\n",
      "Processing row 20200/20604\n",
      "Processing row 20250/20604\n",
      "Processing row 20300/20604\n",
      "Processing row 20350/20604\n",
      "Processing row 20400/20604\n",
      "Processing row 20450/20604\n",
      "Processing row 20500/20604\n",
      "Processing row 20550/20604\n",
      "Processing row 20600/20604\n",
      "\n",
      "Evaluating fine-tuned model on CoSQA test set.\n",
      "Datasets loaded.\n",
      "Query vector database loaded from file\n",
      "Code vector database loaded from file for finetuned model\n",
      "Using device for code embedding model: cuda\n",
      "Loaded model weights from fine-tuned_models/code_model_finetuned_train.pth\n",
      "Using device for nlp embedding model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall@10 for code embeddings: 452/500 = 0.9040\n",
      "Recall@10 for query embeddings: 440/500 = 0.8800\n",
      "\n",
      "MRR@10 for code embeddings: 347.99999999999994/500 = 0.6960\n",
      "MRR@10 for query embeddings: 324.3527777777777/500 = 0.6487\n",
      "\n",
      "NDCG@10 for code embeddings: 373.4832661627109/500 = 0.7470\n",
      "NDCG@10 for query embeddings: 352.5450813293562/500 = 0.7051\n"
     ]
    }
   ],
   "source": [
    "from evaluate_model import evaluate_model\n",
    "from create_vector_db_from_CoSQA import create_vector_db_from_cosqa\n",
    "from fine_tune_model_code import fine_tune_code_model\n",
    "\n",
    "print(\"Training on train split\")\n",
    "#fine_tune_code_model(split=\"train\") # Uncomment to retrain\n",
    "\n",
    "print(\"\\nCreating vector DB from CoSQA corpus with fine-tuned model and evaluating.\")\n",
    "create_vector_db_from_cosqa(code_model_path=\"fine-tuned_models/code_model_finetuned_train.pth\", split=\"train\")\n",
    "\n",
    "print(\"\\nEvaluating fine-tuned model on CoSQA test set.\")\n",
    "evaluate_model(code_model_path=\"fine-tuned_models/code_model_finetuned_train.pth\", split = \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56f85b",
   "metadata": {},
   "source": [
    "As we can see after training 1/2 epoch on train split of dataset we reach Recall@10 = 0.9040 MRR@10 = 0.6960 and NDCG@10 = 0.7570. Recall@10 improved while the two another came out worse!. Maybe longer training would help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1f6d1",
   "metadata": {},
   "source": [
    "Vector database parameters:\n",
    "- connectivity : Edges per node in ANN (Approximate Nearest Neighbour) for more efficient retrieval of closest vectors.\n",
    "- expansion_add : Parameters that tells to how many existing nodes can we connect our new node in ANN.\n",
    "- expansion_search : Number of neighbours we traverse when performing search in ANN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
